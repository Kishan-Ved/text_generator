{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Text Generator based on next character prediction\n",
        "\n",
        "Made using a simple 2 hidden layered Neural Network, this text generator can predict next characters of the input text provided.\n",
        "\n",
        "Here, the intension is not to generate meaningful sentences, we require a lot of compute for that. This app aims at showing how a vanilla neural network is also capable of capturing the format of English language, and generate words that are (very close to) valid words. Notice that the model uses capital letters (including capital I), punctuation marks and fullstops nearly correct. The text is generated paragraph wise, because the model learnt this from the text corpus.\n",
        "\n",
        "This model was trained on a simple 600 KB text corpus titled: 'Gulliver's Travels'\n",
        "\n",
        "Streamlit application: [Link](https://skynet-text-generator-ml.streamlit.app/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTGikjnCSp8d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3v8er8ZwSp8e",
        "outputId": "112a19ed-a611-40fc-b7e6-6adb661aa8b1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.1+cu121'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L89r_0zBSp8f"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh5V7-6cSp8f",
        "outputId": "058922fe-ec97-4d6b-d194-c7f4c13734ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZzs8S-jSp8f"
      },
      "outputs": [],
      "source": [
        "# Open the file in read mode\n",
        "with open('gt.txt', 'r') as file:\n",
        "    # Read the entire content of the file\n",
        "    thefile = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD1fFnx3KxLB"
      },
      "outputs": [],
      "source": [
        "# thefile = thefile.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llwZDGYTHTRB"
      },
      "outputs": [],
      "source": [
        "content = thefile[:-2000]\n",
        "test = thefile[-2000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNGNto0_HkYh",
        "outputId": "96e9bd31-a9db-4c04-d52b-aab1bb473bc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(567139, 2000)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(content), len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URe340wa9WQN",
        "outputId": "14fdddf0-cbe6-48a7-d699-252eace8210d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "print(type(content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgzeYT8YSp8f"
      },
      "outputs": [],
      "source": [
        "# words = pd.read_csv('names-long.csv')[\"Name\"]\n",
        "# words = words.str.lower()\n",
        "# words = words.str.strip()\n",
        "# words = words.str.replace(\" \", \"\")\n",
        "\n",
        "# words = words[words.str.len() > 2]\n",
        "# words = words[words.str.len() < 10]\n",
        "\n",
        "# # Randomly shuffle the words\n",
        "# words = words.sample(frac=1).reset_index(drop=True)\n",
        "# words = words.tolist()\n",
        "\n",
        "# # Remove words having non alphabets\n",
        "# words = [word for word in words if word.isalpha()]\n",
        "# words[:10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHXM2rrrSp8g",
        "outputId": "8f620061-5ff7-4836-b912-73623c59689f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'@': 0, '\\n': 1, ' ': 2, '!': 3, '(': 4, ')': 5, ',': 6, '-': 7, '.': 8, '0': 9, '1': 10, '2': 11, '3': 12, '4': 13, '5': 14, '6': 15, '7': 16, '8': 17, '9': 18, ':': 19, ';': 20, '?': 21, 'A': 22, 'B': 23, 'C': 24, 'D': 25, 'E': 26, 'F': 27, 'G': 28, 'H': 29, 'I': 30, 'J': 31, 'K': 32, 'L': 33, 'M': 34, 'N': 35, 'O': 36, 'P': 37, 'Q': 38, 'R': 39, 'S': 40, 'T': 41, 'U': 42, 'V': 43, 'W': 44, 'X': 45, 'Y': 46, '[': 47, ']': 48, 'a': 49, 'b': 50, 'c': 51, 'd': 52, 'e': 53, 'f': 54, 'g': 55, 'h': 56, 'i': 57, 'j': 58, 'k': 59, 'l': 60, 'm': 61, 'n': 62, 'o': 63, 'p': 64, 'q': 65, 'r': 66, 's': 67, 't': 68, 'u': 69, 'v': 70, 'w': 71, 'x': 72, 'y': 73, 'z': 74, 'æ': 75, 'œ': 76, '–': 77, '—': 78, '‘': 79, '’': 80, '“': 81, '”': 82}\n"
          ]
        }
      ],
      "source": [
        "# Create a dictionary to store unique characters and their indices\n",
        "stoi = {}\n",
        "stoi['@'] = 0\n",
        "\n",
        "# Iterate through each character in the string\n",
        "i = 1\n",
        "for char in sorted(content):\n",
        "    # Check if the character is not already in the dictionary\n",
        "    if char not in stoi:\n",
        "        # Add the character to the dictionary with its index\n",
        "        stoi[char] = i\n",
        "        i+=1\n",
        "\n",
        "# Print the dictionary\n",
        "print(stoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct-nOawu-ygS",
        "outputId": "17ea97f6-c4bc-4270-bb3c-1c7cdc387683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: '@', 1: '\\n', 2: ' ', 3: '!', 4: '(', 5: ')', 6: ',', 7: '-', 8: '.', 9: '0', 10: '1', 11: '2', 12: '3', 13: '4', 14: '5', 15: '6', 16: '7', 17: '8', 18: '9', 19: ':', 20: ';', 21: '?', 22: 'A', 23: 'B', 24: 'C', 25: 'D', 26: 'E', 27: 'F', 28: 'G', 29: 'H', 30: 'I', 31: 'J', 32: 'K', 33: 'L', 34: 'M', 35: 'N', 36: 'O', 37: 'P', 38: 'Q', 39: 'R', 40: 'S', 41: 'T', 42: 'U', 43: 'V', 44: 'W', 45: 'X', 46: 'Y', 47: '[', 48: ']', 49: 'a', 50: 'b', 51: 'c', 52: 'd', 53: 'e', 54: 'f', 55: 'g', 56: 'h', 57: 'i', 58: 'j', 59: 'k', 60: 'l', 61: 'm', 62: 'n', 63: 'o', 64: 'p', 65: 'q', 66: 'r', 67: 's', 68: 't', 69: 'u', 70: 'v', 71: 'w', 72: 'x', 73: 'y', 74: 'z', 75: 'æ', 76: 'œ', 77: '–', 78: '—', 79: '‘', 80: '’', 81: '“', 82: '”'}\n"
          ]
        }
      ],
      "source": [
        "itos = {value: key for key, value in stoi.items()}\n",
        "\n",
        "# Print the interchanged dictionary\n",
        "print(itos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iATLCbSYFX0P"
      },
      "outputs": [],
      "source": [
        "block_size = 120 # context length: how many characters do we take to predict the next one?\n",
        "X, Y = [], []\n",
        "for i in range(len(content)-block_size-2):\n",
        "  X.append([stoi[x] for x in content[i:i+block_size]])\n",
        "  Y.append(stoi[content[i+block_size]])\n",
        "\n",
        "# Move data to GPU\n",
        "\n",
        "X = torch.tensor(X).to(device)\n",
        "Y = torch.tensor(Y).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrM4OkxnEHwN",
        "outputId": "829e762d-0c23-4044-837c-438432891c4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[37, 22, 39,  ..., 63,  2, 68],\n",
              "        [22, 39, 41,  ...,  2, 68, 66],\n",
              "        [39, 41,  2,  ..., 68, 66, 49],\n",
              "        ...,\n",
              "        [69, 53, 67,  ..., 53,  6,  2],\n",
              "        [53, 67, 68,  ...,  6,  2, 60],\n",
              "        [67, 68, 57,  ...,  2, 60, 49]], device='cuda:0')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv5xmY1VG8D4",
        "outputId": "e61af3cb-03a0-421b-912b-76025a649673"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([66, 49, 70,  ..., 60, 49, 70], device='cuda:0')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VqFs0Q_Sp8g",
        "outputId": "259a53fb-40d2-4427-f9c6-9c0bf1c4c935"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([567017, 120]), torch.int64, torch.Size([567017]), torch.int64)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, X.dtype, Y.shape, Y.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiZLCyo5Sp8h"
      },
      "outputs": [],
      "source": [
        "# Embedding layer for the context\n",
        "\n",
        "emb_dim = 10\n",
        "emb = torch.nn.Embedding(len(stoi), emb_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce5JiB4MSp8h",
        "outputId": "87216741-b4e1-4727-f0b1-1ad498c08d1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 6.8964e-01,  1.1622e+00,  8.3505e-02, -2.3599e-01,  6.2329e-01,\n",
              "          6.1196e-01,  1.3798e+00, -5.3010e-01, -7.0471e-01, -5.8698e-01],\n",
              "        [ 2.0053e-01,  5.4518e-01, -6.2755e-01,  2.3470e+00, -8.9879e-01,\n",
              "          2.0934e-01, -1.5553e+00,  1.1621e+00, -7.3243e-01,  4.8444e-01],\n",
              "        [-7.9547e-01,  9.3606e-01, -9.9410e-01,  2.5048e-01,  4.5808e-01,\n",
              "          1.2049e+00, -1.5866e-01, -7.2878e-01,  2.1527e+00,  9.0378e-01],\n",
              "        [-1.4879e+00,  1.1102e-02, -1.2337e-01,  4.1331e-01,  1.8910e-01,\n",
              "         -5.3438e-01,  6.7817e-01,  5.4391e-01,  9.7073e-01,  1.9197e+00],\n",
              "        [ 1.5457e-01, -1.7849e+00, -4.6840e-01,  1.1649e+00, -8.9022e-01,\n",
              "          1.2454e+00, -5.7183e-01, -5.5144e-01,  1.3761e+00, -2.2452e-01],\n",
              "        [-4.8251e-01, -1.0155e+00,  3.7058e-01,  1.1520e+00,  5.4755e-01,\n",
              "          1.0981e+00, -9.6724e-02, -6.4712e-02, -2.4221e+00,  2.0666e-02],\n",
              "        [ 4.9746e-01, -1.2004e+00,  8.3133e-01, -6.0261e-01,  4.1018e-01,\n",
              "          2.2461e-01,  6.9751e-01, -7.2823e-01, -6.5322e-01, -1.0046e+00],\n",
              "        [ 2.2931e-01,  1.8593e+00, -4.4623e-01,  3.0646e-02, -1.5862e+00,\n",
              "          7.0099e-01,  3.6708e-01, -3.1638e-01,  2.2185e-01,  7.6991e-01],\n",
              "        [-6.7786e-01, -6.0262e-02, -3.6143e-01,  7.9780e-01, -1.0888e-01,\n",
              "          2.0295e+00, -3.6247e-01,  5.0309e-01, -1.8469e-01,  2.6439e-01],\n",
              "        [-1.3131e-01, -8.6818e-01, -3.3537e-01, -8.8702e-01,  1.8213e+00,\n",
              "          1.1849e+00,  1.1794e+00,  6.4088e-01, -9.9919e-01, -1.6738e-01],\n",
              "        [ 9.6886e-01, -9.3833e-01, -3.8776e-01, -1.5690e+00, -8.3951e-01,\n",
              "          9.2643e-01, -1.2193e+00,  1.1561e+00,  1.1487e+00,  2.3005e+00],\n",
              "        [-2.4301e-01,  1.3337e+00,  3.7723e-01,  4.1792e-01,  5.3355e-01,\n",
              "          9.4491e-01, -7.0082e-01,  7.0282e-01,  1.4804e+00, -2.3812e-01],\n",
              "        [ 8.1932e-01, -6.6864e-01,  5.1560e-02,  6.1357e-01, -1.3347e+00,\n",
              "          8.0885e-01,  1.9998e+00,  1.6206e+00, -1.6718e+00, -4.8431e-01],\n",
              "        [-5.6027e-01, -1.9112e-02, -1.8225e+00, -1.5762e-01, -7.1426e-01,\n",
              "         -5.1869e-01,  1.0847e+00, -6.5934e-01, -3.9135e-01,  6.1476e-01],\n",
              "        [ 5.4860e-01, -8.1909e-01,  1.6831e+00, -6.0704e-01,  6.3860e-01,\n",
              "         -3.9318e-01,  1.3725e+00, -8.4335e-01,  1.1167e+00, -1.1083e+00],\n",
              "        [ 2.3933e-01, -1.3426e+00, -7.8857e-01, -9.9598e-01,  1.3066e+00,\n",
              "          1.0999e+00,  5.3641e-01, -1.3258e+00,  3.8215e-01, -8.0086e-01],\n",
              "        [-6.4560e-01, -4.7380e-01,  2.3559e+00, -9.2980e-01, -3.5910e-01,\n",
              "          6.8852e-01, -9.7688e-01,  1.3275e+00, -1.1295e+00,  2.8212e-01],\n",
              "        [ 1.6403e-01,  2.1862e-01,  1.3596e+00, -1.2229e+00, -1.2502e+00,\n",
              "         -8.6433e-01, -3.8922e-01,  7.2274e-01, -2.9926e-01,  3.1933e-01],\n",
              "        [-1.0071e+00,  3.4215e+00, -8.4503e-01,  5.6302e-01, -3.7596e-01,\n",
              "         -4.6368e-01, -9.3055e-01,  3.4782e-02,  2.9819e-02,  2.4440e-01],\n",
              "        [-1.1525e+00,  5.3904e-02,  2.9969e-01, -1.7405e+00,  1.3683e+00,\n",
              "          7.3694e-02, -1.8580e-01,  8.2484e-01, -7.0763e-02,  1.4230e+00],\n",
              "        [-7.4020e-01,  1.3680e+00, -6.6513e-01,  4.4388e-01,  7.8338e-02,\n",
              "         -1.1410e+00, -1.3696e-01, -5.7271e-01,  1.2320e+00,  6.8225e-01],\n",
              "        [-2.2002e+00, -5.1073e-01, -6.7942e-01, -2.3487e-01, -9.5829e-01,\n",
              "         -5.0894e-01,  2.4753e+00,  1.3637e+00,  8.5288e-01, -1.0035e-01],\n",
              "        [-2.8172e-01,  7.8035e-01,  1.0322e+00,  7.9473e-01,  6.6819e-01,\n",
              "          3.3725e-01,  9.6886e-03,  2.8452e-01, -2.8073e+00,  5.9224e-01],\n",
              "        [-1.6347e+00, -8.1827e-01, -1.2939e+00,  1.6866e+00,  2.5681e+00,\n",
              "         -8.2604e-01,  5.8630e-01,  4.7617e-01, -4.3023e-01,  8.0676e-01],\n",
              "        [ 9.0952e-01,  1.1255e+00,  1.1055e+00,  9.8933e-01,  1.2603e+00,\n",
              "          9.7050e-01, -9.1567e-01, -3.7785e-01,  1.0629e+00, -2.8678e-01],\n",
              "        [ 1.8597e+00,  1.1796e+00, -1.5772e-01, -6.2047e-02, -7.3761e-01,\n",
              "         -2.4894e-01, -2.0927e-01, -3.4039e-01, -1.6279e+00,  3.7177e-01],\n",
              "        [-2.7202e-01,  2.5092e-01, -2.9356e-01, -1.6109e-01,  2.5104e-01,\n",
              "         -3.6964e-01,  1.9155e+00, -4.2203e-02,  2.1383e-02,  1.3786e+00],\n",
              "        [-8.1798e-01,  2.0949e-01,  1.9087e-01,  7.9926e-01,  2.1833e-01,\n",
              "         -3.8569e-01, -5.9966e-01,  8.2917e-01,  9.2859e-01,  7.0202e-01],\n",
              "        [-5.5815e-01, -8.2435e-01, -3.1158e-01, -1.9211e+00, -3.1296e-01,\n",
              "          9.3286e-02,  6.9267e-01, -2.2579e-01,  1.9655e+00, -7.0494e-01],\n",
              "        [-5.5359e-01,  1.6256e-01,  1.1122e+00, -5.7338e-01,  4.8699e-02,\n",
              "         -7.4159e-01, -7.9928e-01, -1.0340e+00, -8.1103e-02,  1.2297e+00],\n",
              "        [ 3.9587e-01,  1.6787e+00,  1.7386e-01,  9.0779e-01,  3.4258e-01,\n",
              "          1.7429e+00, -2.4829e-01,  3.6205e-01, -4.7033e-01,  1.3544e+00],\n",
              "        [-2.1994e-01, -1.1562e+00, -4.6472e-01, -1.2770e-01,  5.8451e-01,\n",
              "         -9.0296e-02, -8.1137e-02,  1.0199e+00, -1.2338e+00, -1.1751e+00],\n",
              "        [-8.3849e-01,  8.1453e-01, -5.4207e-01, -1.5403e+00, -2.1906e+00,\n",
              "         -4.9597e-01, -1.1596e-01,  1.9607e+00,  2.1737e-01,  1.4536e+00],\n",
              "        [ 1.2243e+00,  3.4790e-01,  2.0595e-01,  6.5139e-02, -5.1328e-01,\n",
              "         -1.1524e+00, -4.7792e-02,  1.6148e+00, -7.9181e-01,  7.8312e-01],\n",
              "        [-6.1316e-01, -1.2798e+00, -1.4941e-02, -1.4089e+00,  8.5810e-01,\n",
              "         -1.5326e-02, -1.3829e+00, -6.7243e-01, -4.9969e-01,  1.0735e+00],\n",
              "        [-1.9439e+00,  7.5016e-01, -1.0096e-01, -7.1226e-01,  7.1528e-01,\n",
              "         -2.3082e-01, -1.1536e+00, -6.4187e-02,  4.1782e-01, -1.9923e+00],\n",
              "        [-6.9157e-01, -4.7584e-01,  1.5696e-01,  1.9061e-02, -1.0339e+00,\n",
              "         -7.0772e-01,  1.4065e+00,  1.4506e+00,  3.8994e-01, -2.0667e+00],\n",
              "        [-1.7081e-01,  1.9894e+00,  3.7522e-01, -1.2514e+00, -1.1802e+00,\n",
              "         -9.4270e-01,  1.2293e+00, -8.2776e-02,  1.0689e+00, -1.6041e+00],\n",
              "        [ 1.9432e+00,  1.3925e+00, -1.9324e-01,  2.9883e-01, -1.6024e-02,\n",
              "          5.1187e-01,  1.3672e-01, -1.1154e-01, -8.2537e-01, -1.1263e+00],\n",
              "        [-4.2665e-02,  6.3495e-02,  1.7265e+00,  2.4400e+00, -1.3498e-01,\n",
              "          5.8855e-01,  2.1424e-01, -1.4343e+00,  2.8403e-01, -7.5770e-03],\n",
              "        [ 3.9352e-03,  3.9191e-01,  7.9092e-01, -1.3922e+00, -8.4889e-01,\n",
              "         -1.7744e-02, -2.8622e-01,  1.5477e-01, -2.7784e-01, -7.8090e-01],\n",
              "        [-9.1567e-02,  1.8693e+00, -1.2294e-02, -1.2217e+00,  9.2260e-01,\n",
              "          9.6382e-01,  7.0103e-01,  4.8269e-01, -1.6582e+00, -6.7200e-01],\n",
              "        [ 4.8466e-01,  4.7285e-02, -4.4313e-01,  1.3292e+00, -1.3807e-01,\n",
              "          7.2109e-01, -4.3021e-01, -5.1551e-01,  1.1446e+00, -2.8832e-02],\n",
              "        [ 1.1886e+00, -1.6409e+00, -2.0670e-01, -2.9125e-01,  1.2240e+00,\n",
              "         -7.4398e-01,  1.7197e+00, -6.2540e-01, -3.5973e-01, -1.0184e+00],\n",
              "        [ 1.6985e+00, -2.5928e-01,  1.8881e+00,  2.2021e-01,  1.0357e-01,\n",
              "          3.5207e-01, -2.1769e-01,  1.3771e+00,  3.6365e-01,  5.3508e-01],\n",
              "        [ 6.8565e-02, -1.6716e-01, -5.2356e-02, -2.3348e+00, -1.1244e-01,\n",
              "         -3.9535e-01,  1.0124e+00,  5.4076e-01, -1.5112e+00, -5.3706e-01],\n",
              "        [-1.2524e+00, -9.2989e-01,  2.4353e-01,  6.7293e-01, -9.9422e-01,\n",
              "         -6.8502e-01, -1.4284e+00,  3.0427e-01,  8.0023e-01, -6.0489e-01],\n",
              "        [ 8.8822e-01,  2.4859e-01,  4.9296e-01, -1.7324e+00, -3.8779e-02,\n",
              "         -1.5757e+00, -6.8525e-01, -6.7644e-01,  1.0265e+00, -1.1068e+00],\n",
              "        [ 4.0465e-01,  1.3712e+00, -2.5015e+00, -1.6083e+00,  7.2967e-02,\n",
              "         -1.3656e-01,  6.8711e-01,  1.0107e+00, -1.6803e-02,  2.9980e-01],\n",
              "        [ 1.6366e+00,  1.3023e-01, -1.0328e-01, -3.7019e-01, -1.4797e+00,\n",
              "         -4.1111e-01,  1.0633e-01,  8.9084e-02,  9.1686e-01,  8.5566e-01],\n",
              "        [ 1.2646e+00,  1.1541e+00,  3.2662e+00,  1.6703e+00, -4.2267e-03,\n",
              "         -3.3866e-01,  7.1951e-01,  2.7377e-01,  6.1500e-01, -6.5508e-01],\n",
              "        [-4.8024e-01,  3.7488e-01, -5.5106e-02,  1.5090e-01, -2.1316e-01,\n",
              "          1.5351e+00,  1.9170e-01,  9.2054e-01, -1.4612e+00, -2.2882e-01],\n",
              "        [-2.1792e+00, -3.9130e-02,  1.9210e-01,  9.4874e-01, -1.0042e+00,\n",
              "          7.0811e-01,  1.5483e+00,  3.0746e-01,  2.0392e-01,  8.1262e-01],\n",
              "        [-1.3888e+00,  9.2206e-01, -2.9995e-01, -5.0652e-01,  4.4108e-02,\n",
              "          1.0777e+00, -1.8159e-01, -4.3776e-01, -1.0870e+00,  3.0308e-01],\n",
              "        [ 1.2394e+00,  9.1919e-01, -7.5247e-01,  2.6004e+00,  7.8712e-01,\n",
              "          9.6877e-01, -4.1785e-01,  8.0852e-01,  1.8297e+00, -1.2204e+00],\n",
              "        [ 4.3696e-01,  6.3126e-01, -1.6062e-01,  1.5237e+00,  2.9686e-01,\n",
              "         -7.7969e-01, -6.9327e-01,  5.4054e-01,  5.8219e-01,  8.8152e-01],\n",
              "        [-1.3773e-01,  5.5323e-01, -8.2107e-01, -6.0610e-01, -1.9638e+00,\n",
              "         -7.6951e-01,  1.1169e+00, -8.5698e-01,  4.9666e-01, -1.2564e-01],\n",
              "        [-6.4014e-01,  3.8042e-01, -1.1386e+00, -9.7801e-01,  1.0107e+00,\n",
              "         -4.0512e-01,  4.8798e-01,  6.2226e-01,  1.3582e+00,  1.4560e-01],\n",
              "        [ 4.2724e-01,  5.2570e-01,  5.6238e-01, -1.8478e+00,  1.4091e-01,\n",
              "         -1.5115e-01, -4.9629e-01,  2.5680e-01,  1.1437e+00, -2.3894e+00],\n",
              "        [-7.8424e-02, -1.5796e+00,  9.9298e-01, -8.6076e-01, -8.5366e-01,\n",
              "         -6.3870e-01,  9.9679e-01, -1.6399e-01, -1.4342e+00, -8.7717e-01],\n",
              "        [-5.8088e-01,  1.2654e+00,  1.6338e+00,  9.3324e-01,  1.5555e+00,\n",
              "          1.0510e+00,  6.7706e-01, -5.3646e-01,  2.2083e+00,  1.4800e+00],\n",
              "        [ 6.8821e-01, -1.6284e-02,  6.1647e-01, -2.7097e+00, -3.4622e-01,\n",
              "         -4.3300e-01,  1.1811e+00,  7.6089e-01,  8.3497e-02,  8.8307e-01],\n",
              "        [ 3.0014e-01,  2.3467e+00,  1.4370e+00, -9.5075e-01,  7.2479e-01,\n",
              "          4.8186e-01, -3.9397e-01,  5.2338e-01, -9.5636e-01, -2.2126e+00],\n",
              "        [-1.0062e+00, -1.1571e+00,  2.4605e-01,  4.9073e-01, -4.6334e-01,\n",
              "          3.7676e-01,  4.0575e-01,  6.5842e-01, -1.4915e+00, -3.0015e+00],\n",
              "        [ 2.4844e-01,  3.7185e-01,  1.6891e+00,  2.0004e-02, -2.5781e-01,\n",
              "         -2.1007e+00,  1.9846e+00, -1.7787e+00, -1.0022e-01,  1.0515e-01],\n",
              "        [-3.6523e-01, -5.9062e-01,  1.8145e+00,  3.0190e-01,  1.3996e+00,\n",
              "         -7.3597e-01,  6.8561e-01,  1.6913e-01,  6.7116e-01,  1.9298e+00],\n",
              "        [ 6.9793e-01, -3.5802e-01, -8.8027e-01, -1.4587e+00, -5.8678e-01,\n",
              "         -1.0923e+00,  1.4128e+00, -1.9980e+00,  4.9612e-01, -5.4764e-01],\n",
              "        [ 1.8322e+00,  8.7559e-01, -6.5329e-01,  1.2726e+00, -3.7450e-01,\n",
              "          9.6694e-01, -6.6092e-02, -2.0944e-01, -5.6054e-01, -1.5172e+00],\n",
              "        [ 1.8482e+00, -8.5198e-01, -6.0784e-01,  1.6802e+00, -1.8484e+00,\n",
              "         -4.1237e-01,  2.0353e-01,  4.9530e-01, -1.1637e+00,  8.1455e-01],\n",
              "        [-1.2157e+00, -7.1000e-01,  1.0070e-01,  1.1856e+00, -5.0211e-01,\n",
              "          9.5001e-01, -3.5267e-01,  1.1463e+00,  1.7477e+00,  8.5705e-01],\n",
              "        [-5.9999e-01, -1.7839e+00,  3.0655e-01,  4.7515e-01,  4.7223e-01,\n",
              "         -6.6654e-01, -3.2577e-03,  4.7839e-01, -6.4757e-02,  7.2044e-01],\n",
              "        [ 1.9760e-01, -3.8009e-01,  8.7977e-01, -1.5791e+00,  1.3000e-01,\n",
              "         -7.7670e-01, -3.4047e-01,  5.5520e-01, -3.7511e-01, -7.7413e-03],\n",
              "        [-6.2179e-01, -4.9021e-01,  5.4244e-01,  1.3133e+00,  1.6162e-01,\n",
              "         -8.9615e-01,  4.4897e-01,  5.5904e-01, -2.3771e-01,  5.9028e-01],\n",
              "        [-1.6581e+00,  4.5522e-01,  1.0753e-01, -1.1382e-01, -5.4397e-01,\n",
              "          1.6279e+00, -9.4056e-01, -1.2337e+00,  1.6003e+00, -5.8020e-01],\n",
              "        [-5.9374e-01,  4.8202e-01,  2.4211e-01, -3.0514e+00, -2.0172e+00,\n",
              "          9.4016e-01,  1.5838e+00,  2.0723e-01, -2.2297e-01,  1.0978e+00],\n",
              "        [ 3.9447e-01, -1.1050e+00, -1.3958e+00, -1.6035e-01, -9.1832e-01,\n",
              "          1.6310e+00,  8.4194e-03,  2.8471e-01, -1.8185e+00, -1.2774e+00],\n",
              "        [-9.6496e-01, -9.2747e-01,  5.3689e-01, -3.9131e-01, -1.6197e+00,\n",
              "          2.8926e-02, -2.8297e-01, -8.7201e-01, -3.1625e-01, -1.9464e+00],\n",
              "        [ 8.5938e-01,  1.2560e-01, -9.8736e-01, -2.2742e+00, -1.0069e+00,\n",
              "         -8.4579e-01,  4.3666e-01,  1.7540e-02,  3.1800e-01, -5.0057e-01],\n",
              "        [-1.1071e+00,  5.4714e-01, -2.3397e-01, -3.8558e-01,  1.1041e+00,\n",
              "          4.2790e-02,  2.4453e-01, -7.4270e-02,  1.6701e+00,  1.3095e+00],\n",
              "        [ 2.5802e+00,  1.2283e+00, -2.1045e-01,  3.7752e-01,  8.3682e-01,\n",
              "         -1.7758e+00,  1.0885e-01, -1.0807e+00,  7.4470e-01,  1.2707e+00],\n",
              "        [ 5.8812e-01, -1.6674e-01,  4.3416e-01, -2.3390e+00, -7.6965e-01,\n",
              "          1.0515e+00,  1.1088e+00,  1.0251e+00, -1.6375e+00,  1.9149e+00],\n",
              "        [ 6.8426e-03,  4.0166e-01, -6.2653e-01, -1.4094e+00, -2.9748e+00,\n",
              "         -1.9776e+00, -9.2882e-02, -2.9054e-01,  1.7038e-02, -5.2234e-01],\n",
              "        [ 7.0973e-01,  7.7507e-02, -1.0654e-01,  1.3670e+00, -9.4174e-02,\n",
              "         -3.3423e-01,  1.4223e+00, -1.6707e-01,  5.8652e-01, -2.3098e-01]],\n",
              "       requires_grad=True)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xBOscmYSp8h",
        "outputId": "6c2a1f5c-70da-4f65-bdf4-4d483775b7a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([83, 10])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb.weight.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajd1dqMfSp8h"
      },
      "outputs": [],
      "source": [
        "# # Function to visualize the embedding in 2d space if 2 dimensions are used\n",
        "\n",
        "# def plot_emb(emb, itos, ax=None):\n",
        "#     if ax is None:\n",
        "#         fig, ax = plt.subplots()\n",
        "#     for i in range(len(itos)):\n",
        "#         x, y = emb.weight[i].detach().cpu().numpy()\n",
        "#         ax.scatter(x, y, color='k')\n",
        "#         ax.text(x + 0.05, y + 0.05, itos[i])\n",
        "#     return ax\n",
        "\n",
        "# plot_emb(emb, itos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zQ6I0k4Sp8h"
      },
      "outputs": [],
      "source": [
        "class NextChar(nn.Module):\n",
        "  def __init__(self, block_size, vocab_size, emb_dim, hidden_size1, hidden_size2):\n",
        "    super().__init__()\n",
        "    self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "    self.lin1 = nn.Linear(block_size * emb_dim, hidden_size1)\n",
        "    self.lin2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "    self.lin3 = nn.Linear(hidden_size2, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.emb(x)\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = torch.sin(self.lin1(x)) # Activation function : change this\n",
        "    x = self.lin2(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzuuwyN-Sp8h",
        "outputId": "1d7314d5-fade-44ed-a3cf-cb3c77d87e41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DJ,PdkG5:(l–7!JgkhaP9mxSK‘et(WuRrz;2tPd6“LCSHM\n"
          ]
        }
      ],
      "source": [
        "# Generate names from untrained model\n",
        "\n",
        "model = NextChar(block_size, len(stoi), emb_dim, 500, 300).to(device)\n",
        "model = torch.compile(model)\n",
        "\n",
        "no_of_chars = 200\n",
        "g = torch.Generator()\n",
        "g.manual_seed(200)\n",
        "def generate_name(model, inp, itos, stoi, block_size, max_len=no_of_chars):\n",
        "\n",
        "    context = [0] * block_size\n",
        "    # inp = inp.lower()\n",
        "    if len(inp) <= block_size:\n",
        "      for i in range(len(inp)):\n",
        "        context[i] = stoi[inp[i]]\n",
        "    else:\n",
        "      for i in range(len(inp)-block_size,len(inp)):\n",
        "        context[i] = stoi[inp[i]]\n",
        "\n",
        "    name = ''\n",
        "    for i in range(max_len):\n",
        "        x = torch.tensor(context).view(1, -1).to(device)\n",
        "        y_pred = model(x)\n",
        "        ix = torch.distributions.categorical.Categorical(logits=y_pred).sample().item()\n",
        "        if ix in itos:\n",
        "          ch = itos[ix]\n",
        "        # if ch == '.':\n",
        "        #     break\n",
        "          name += ch\n",
        "          context = context[1:] + [ix]\n",
        "    return name\n",
        "\n",
        "print(generate_name(model, \"@\", itos, stoi, block_size, no_of_chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdLFLtH7Sp8h",
        "outputId": "05351a98-51cc-44b8-9f74-0a7aaead4cc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_orig_mod.emb.weight torch.Size([83, 10])\n",
            "_orig_mod.lin1.weight torch.Size([500, 1200])\n",
            "_orig_mod.lin1.bias torch.Size([500])\n",
            "_orig_mod.lin2.weight torch.Size([300, 500])\n",
            "_orig_mod.lin2.bias torch.Size([300])\n",
            "_orig_mod.lin3.weight torch.Size([83, 300])\n",
            "_orig_mod.lin3.bias torch.Size([83])\n"
          ]
        }
      ],
      "source": [
        "for param_name, param in model.named_parameters():\n",
        "    print(param_name, param.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajuxFzmFSp8h",
        "outputId": "1e9acd3f-24b0-48df-f892-477151f0efc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 2.2945427894592285\n",
            "10 0.8446438312530518\n",
            "20 0.7583667635917664\n",
            "30 0.7739819288253784\n",
            "40 0.7692346572875977\n",
            "50 0.6106970310211182\n",
            "60 0.5997738242149353\n",
            "70 0.5012879967689514\n",
            "80 0.493354469537735\n",
            "90 0.4942704439163208\n",
            "100 0.4229840934276581\n",
            "110 0.3926779627799988\n",
            "120 0.3828011155128479\n",
            "130 0.39322641491889954\n",
            "140 0.4038969576358795\n",
            "150 0.3873109221458435\n",
            "160 0.35438305139541626\n",
            "170 0.37257158756256104\n",
            "180 0.38877421617507935\n",
            "190 0.3960263431072235\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
        "import time\n",
        "# Mini-batch training\n",
        "batch_size = 4096\n",
        "print_every = 10\n",
        "elapsed_time = []\n",
        "for epoch in range(200):\n",
        "    start_time = time.time()\n",
        "    for i in range(0, X.shape[0], batch_size):\n",
        "        x = X[i:i+batch_size]\n",
        "        y = Y[i:i+batch_size]\n",
        "        y_pred = model(x)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    end_time = time.time()\n",
        "    elapsed_time.append(end_time - start_time)\n",
        "    if epoch % print_every == 0:\n",
        "        print(epoch, loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LbBOB11Sp8i"
      },
      "outputs": [],
      "source": [
        "# # Visualize the embedding\n",
        "\n",
        "# plot_emb(model.emb, itos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsCmot1ySp8i",
        "outputId": "a4e427ce-6080-48af-a37d-23248d84044d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " the saw the pars parion of the folt not have the deat thes ballon umarased, and a c fundupuintowayed the sevrimey the wing my severaltion; these sriegs.\n",
            "\n",
            "I spok any of malien, and his eiriotd vawn napw of plangdent as I  clay dory cof on seaml fasured ived I ray wmyared, hage “heittabre fortps saaghte the severs, whede unhiph vh\n",
            "ses vistat instred mane besce to delsw, houghfc sewere, and whrf in knekn, amonges is tail or my houadly on ro tot excomicise. I”usagale wisels indevel hirif my mastitale of qncear of the moring lagost for well cour mompliethitten tare finhl me weand de, and my habreavous the homeblratenn, and in the every cane. In of it to leasy Yahe ink cirtled with bimen alay dut of the phandever not do which I had have made domith of the natiel yot; bown iccourh I her somalh; treards, which in to the co take of them they to to coal him the comp mistive a oln fourne ut my moint on gost of a do nuct: “l edeicg, they hams; satiled wont teavinedy him rovent lay ragly and aming\n"
          ]
        }
      ],
      "source": [
        "# Generate text from the trained model\n",
        "print(generate_name(model, \"I love travelling around the \", itos, stoi, block_size, 1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hE_1VGy3CVeZ"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(),\"gt_eng_model_upper_two_hid_layer_emb10.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "554axn0-Sp8i"
      },
      "source": [
        "#### Tuning knobs\n",
        "\n",
        "1. Embedding size\n",
        "2. MLP\n",
        "3. Context length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Streamlit Application\n",
        "Explore changes in the text generated based on Embedding size, block size and seed text in the streamlit application: \n",
        "[Link](https://skynet-text-generator-ml.streamlit.app/)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
